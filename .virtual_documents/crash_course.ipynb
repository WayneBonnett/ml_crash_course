





























import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import mean_squared_error, r2_score











# Generate random data
np.random.seed(0)  # For reproducibility
x = np.random.rand(100).reshape(-1, 1) # we have to reshape to make python happy 
y = 2 * x + 1 + np.random.randn(100).reshape(-1, 1) * 0.5

data = pd.DataFrame({'Weight (mg) -> x': x.flatten(), 'Length (cm) -> y': y.flatten()}) # just for viewing our data
data.head()


# Plotting the points
plt.scatter(x, y)
plt.title("Earthworm Data")
plt.xlabel("Earthworm weight in mg")
plt.ylabel("Earthworm length in cm")
plt.show()














# Split the data into training and testing sets 
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)


x_train[0:5]


y_train[0:5]


# we did an 80 / 20 split which is common 
print(f"Total size of x: {len(x)}\n size of x_train: {len(x_train)}\n size of x_test: {len(x_test)}")








# Fit the model 
model = LinearRegression() 
model.fit(x_train, y_train)





# Make predictions 
# _pred for prediction is a common convention
y_pred = model.predict(x_test)

y_pred[0:5]


# Evaluate the model 
mse = mean_squared_error(y_test, y_pred) 
r2 = r2_score(y_test, y_pred) 

# Print the results 
print("Coefficients:", model.coef_) 
print("Intercept:", model.intercept_) 
print("Mean Squared Error:", mse) 
print("R-squared:", r2)









